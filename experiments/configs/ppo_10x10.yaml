# PPO configuration for 10x10 grid
env:
  grid_size: 10
  sensor_radius: 3
  initial_battery: 100.0
  battery_depletion_rate: 1.0
  max_steps: 500
  num_targets: 1
  obstacle_density: 0.1
  detection_probability: 0.95

  # Rewards
  reward_target_found: 1000.0
  reward_new_coverage: 1.0
  reward_time_penalty: -1.0
  reward_battery_depleted: -500.0
  reward_prob_gradient: 5.0

training:
  total_timesteps: 500000
  n_envs: 4
  feature_extractor: "compact"
  features_dim: 128

  # PPO specific
  learning_rate: 0.0003
  n_steps: 2048
  batch_size: 64
  n_epochs: 10
  gamma: 0.99
  gae_lambda: 0.95
  clip_range: 0.2
  ent_coef: 0.01

  # Evaluation
  eval_freq: 10000
  n_eval_episodes: 20
  checkpoint_freq: 50000
